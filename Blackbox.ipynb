{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emanu\\Analysis-on-Churn-Banking-Modeling-Dataset\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Metric and model form scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "# Boosting model\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# Tuning optimization\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "# System utilities\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and cleaning of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flag_Richiesta_Estinzione_cc</th>\n",
       "      <th>Imp_Valore_del_Cliente</th>\n",
       "      <th>Flag_Apertura_Conto_Online</th>\n",
       "      <th>Flag_Possesso_piu_Conti</th>\n",
       "      <th>Eta</th>\n",
       "      <th>Provincia_Domicilio</th>\n",
       "      <th>Provincia_Residenza</th>\n",
       "      <th>Anno_Apertura_primo_Conto</th>\n",
       "      <th>Professione</th>\n",
       "      <th>Imp_Reddito</th>\n",
       "      <th>...</th>\n",
       "      <th>Imp_Liquidit�_Attuale</th>\n",
       "      <th>Imp_Gestito_attuale</th>\n",
       "      <th>Imp_Amministrato_attuale</th>\n",
       "      <th>Imp_Liquidit�_Attuale_6m</th>\n",
       "      <th>Imp_Gestito_attuale_6m</th>\n",
       "      <th>Imp_Amministrato_attuale_6m</th>\n",
       "      <th>Flag_Trasferimento_Titoli_Out</th>\n",
       "      <th>Flag_Rifiuto_Carte</th>\n",
       "      <th>Flag_Rifiuto_Prestiti</th>\n",
       "      <th>Flag_Disattivazione_RID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>65.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>BO</td>\n",
       "      <td>BO</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Impiegato</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1634.57</td>\n",
       "      <td>2978.40</td>\n",
       "      <td>2980.92</td>\n",
       "      <td>1550.44</td>\n",
       "      <td>2853.2</td>\n",
       "      <td>2853.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>138.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>SA</td>\n",
       "      <td>SA</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Impiegato</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11918.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34916.15</td>\n",
       "      <td>26122.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22053.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>546.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>VT</td>\n",
       "      <td>VT</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Altro/Nessuno</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2671.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232776.62</td>\n",
       "      <td>16545.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216304.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>68.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>MI</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Impiegato</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19211.31</td>\n",
       "      <td>15013.53</td>\n",
       "      <td>15017.53</td>\n",
       "      <td>12500.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>2417.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>MI</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Quadro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1526.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1427.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21514.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Flag_Richiesta_Estinzione_cc  Imp_Valore_del_Cliente  \\\n",
       "0                           no                   65.03   \n",
       "1                           no                  138.88   \n",
       "2                           no                  546.54   \n",
       "3                           no                   68.69   \n",
       "4                           no                 2417.05   \n",
       "\n",
       "   Flag_Apertura_Conto_Online  Flag_Possesso_piu_Conti   Eta  \\\n",
       "0                           0                        0  38.0   \n",
       "1                           0                        0  45.0   \n",
       "2                           0                        0  61.0   \n",
       "3                           0                        0  33.0   \n",
       "4                           0                        0  36.0   \n",
       "\n",
       "  Provincia_Domicilio Provincia_Residenza  Anno_Apertura_primo_Conto  \\\n",
       "0                  BO                  BO                     2004.0   \n",
       "1                  SA                  SA                     2000.0   \n",
       "2                  VT                  VT                     2005.0   \n",
       "3                  MI                  MI                     2010.0   \n",
       "4                  MI                  MI                     2001.0   \n",
       "\n",
       "     Professione  Imp_Reddito  ... Imp_Liquidit�_Attuale Imp_Gestito_attuale  \\\n",
       "0      Impiegato          3.0  ...               1634.57             2978.40   \n",
       "1      Impiegato          4.0  ...              11918.26                 NaN   \n",
       "2  Altro/Nessuno          4.0  ...               2671.95                 NaN   \n",
       "3      Impiegato          2.0  ...              19211.31            15013.53   \n",
       "4         Quadro          NaN  ...               1526.38                 NaN   \n",
       "\n",
       "   Imp_Amministrato_attuale  Imp_Liquidit�_Attuale_6m  Imp_Gestito_attuale_6m  \\\n",
       "0                   2980.92                   1550.44                  2853.2   \n",
       "1                  34916.15                  26122.17                     NaN   \n",
       "2                 232776.62                  16545.25                     NaN   \n",
       "3                  15017.53                  12500.00                     NaN   \n",
       "4                       NaN                   1427.70                     NaN   \n",
       "\n",
       "   Imp_Amministrato_attuale_6m  Flag_Trasferimento_Titoli_Out  \\\n",
       "0                      2853.22                              0   \n",
       "1                     22053.82                              0   \n",
       "2                    216304.33                              1   \n",
       "3                          NaN                              0   \n",
       "4                     21514.60                              0   \n",
       "\n",
       "   Flag_Rifiuto_Carte  Flag_Rifiuto_Prestiti  Flag_Disattivazione_RID  \n",
       "0                   0                      0                        0  \n",
       "1                   0                      0                        0  \n",
       "2                   0                      0                        0  \n",
       "3                   0                      0                        0  \n",
       "4                   0                      0                        0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"Clean_dataset.csv\") # Data cleaning and feature engineering done in Feature_Engineering.ipynb\n",
    "df = df.drop('Id_Cliente',axis=1) # No need cause it was confusing the model\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Flag_Richiesta_Estinzione_cc', axis=1)\n",
    "y = df['Flag_Richiesta_Estinzione_cc'].map({'no': 0, 'si': 1})  \n",
    "XX = pd.get_dummies(X) # It will be useful later to ensure that the column size of all the df is the same (Provincia and Residenza were giving us problem due to their unique values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_names(df):\n",
    "    df.columns = [col.replace(' ', '_').replace('[', '').replace(']', '').replace('<', '') for col in df.columns]\n",
    "    return df\n",
    "# After creating dummies, the model was not able to elaborate certain columns due to the presence of certain special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # Split 4:5, random state to ensure reproducibility\n",
    "# To ensure that the size is the same even after the split\n",
    "XX = pd.get_dummies(pd.concat([X_train, X_test], sort=False)) \n",
    "X_train, X_test = XX.loc[X_train.index], XX.loc[X_test.index]\n",
    "# apply clean_feature_names\n",
    "X_train = clean_feature_names(X_train)\n",
    "X_test = clean_feature_names(X_test)\n",
    "\n",
    "X_train, X_test = X_train.align(X_test, join='inner', axis=1)\n",
    "# I didn't know if the code would confuse the df of the last tuning with the final one, i changed names to ensure this don't happen\n",
    "X_train_final = X_train\n",
    "X_test_final = X_test\n",
    "y_train_final = y_train\n",
    "y_test_final = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and cleaning of our synthetic dataset previously generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df = pd.read_csv(r\"Synthetic_dataset.csv\")\n",
    "synthetic_df = synthetic_df.drop('Id_Cliente',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the same feature engineering process for the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df=synthetic_df\n",
    "synthetic_df['Professione'] = synthetic_df['Professione'].apply(lambda x: 'Ufficiale/Sottoufficiale' if x == 'Ufficiale/Sottufficiale' else \n",
    "                                                                  'Libero professionista/Titolare impresa' if x == 'Libero professionista/Titolare di impresa' else \n",
    "                                                                  x)\n",
    "synthetic_df['Provincia_Residenza'] = synthetic_df['Provincia_Residenza'].replace('FO', 'FC')\n",
    "synthetic_df['Provincia_Domicilio'] = synthetic_df['Provincia_Domicilio'].replace('FO', 'FC')\n",
    "\n",
    "synthetic_df['Provincia_Residenza'] = synthetic_df['Provincia_Residenza'].replace('PS', 'PU')\n",
    "synthetic_df['Provincia_Domicilio'] = synthetic_df['Provincia_Domicilio'].replace('PS', 'PU')\n",
    "\n",
    "synthetic_df['Provincia_Domicilio'] = synthetic_df['Provincia_Domicilio'].replace('8N', np.nan)\n",
    "synthetic_df['Provincia_Domicilio'] = synthetic_df['Provincia_Domicilio'].replace('BE', np.nan)\n",
    "mapping = {\n",
    "    'CAUTO': 1,\n",
    "    'PRUDENTE': 2,\n",
    "    'BILANCIATO': 3,\n",
    "    'DINAMICO':4,\n",
    "    'ND':0\n",
    "}\n",
    "synthetic_df['Profilo_MIFID'] = synthetic_df['Profilo_MIFID'].replace(mapping)\n",
    "\n",
    "mapping2 = {\n",
    "    'Bassissimo (<1200)': 1,\n",
    "    'Basso (tra 1200 e 1500)': 2,\n",
    "    'Medio (tra 1500 e 1800)': 3,\n",
    "    'Alto (tra 1800 e 2500)':4,\n",
    "    'Altissimo (>2500)':5\n",
    "}\n",
    "\n",
    "synthetic_df['Imp_Reddito'] = synthetic_df['Imp_Reddito'].replace(mapping2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_synthetic = synthetic_df.drop('Flag_Richiesta_Estinzione_cc', axis=1)\n",
    "y_synthetic = synthetic_df['Flag_Richiesta_Estinzione_cc'].map({'no': 0, 'si': 1})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (70000, 279)\n"
     ]
    }
   ],
   "source": [
    "# Same process as before to ensure that column lenght is the same since once we train our model with specific columns, we need to ensure that our model has in input a df with same lenght and names\n",
    "X_synthetic = pd.get_dummies(X_synthetic)\n",
    "X_train_synthetic = clean_feature_names(X_synthetic)\n",
    "\n",
    "missing_columns_train = set(XX.columns) - set(X_train_synthetic.columns)\n",
    "for col in missing_columns_train:\n",
    "    X_train_synthetic[col] = 0  \n",
    "\n",
    "X_train_res_synthetic = X_train_synthetic[XX.columns]\n",
    "\n",
    "print(\"Training features:\", X_train_res_synthetic.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We stopped the tuning earlier since we found a good set of parameters and tuning wasn't giving us better results but was converging to the same parameters\n",
    "'''\n",
    "[I 2024-04-23 17:36:46,835] Trial 26 finished with value: 0.8232704402515724 and parameters: {'n_estimators': 297, 'learning_rate': 0.010065762501114987, 'max_depth': 13, 'num_leaves': 25, 'min_child_samples': 28, 'subsample': 0.9186047768818155, 'subsample_freq': 5, 'colsample_bytree': 0.8969786318428297, 'reg_alpha': 0.9097824682690728, 'reg_lambda': 0.6075396766185748, 'max_bin': 289}. Best is trial 26 with value: 0.8232704402515724.\n",
    "'''\n",
    "scale_pos_weight = len(y[y == 0]) / len(y[y == 1])\n",
    "\n",
    "best_params = {\n",
    "    \"n_estimators\": 297,\n",
    "    \"learning_rate\": 0.010065762501114987,\n",
    "    \"max_depth\": 13,\n",
    "    \"num_leaves\": 25,\n",
    "    \"min_child_samples\": 28,\n",
    "    \"subsample\": 0.9186047768818155,\n",
    "    \"subsample_freq\": 5,\n",
    "    \"colsample_bytree\": 0.8969786318428297,\n",
    "    \"reg_alpha\": 0.9097824682690728,\n",
    "    \"reg_lambda\": 0.6075396766185748,\n",
    "    \"max_bin\": 289,\n",
    "    'force_col_wise': True,\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "best_lgb_classifier = lgb.LGBMClassifier(**best_params)\n",
    "best_lgb_classifier.fit(X_train_final, y_train_final)\n",
    "lgbm_predictions = best_lgb_classifier.predict_proba(X_test_final)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "'''\n",
    "Best Hyperparameters: {'n_estimators': 661, 'learning_rate': 0.036491004518573594, 'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.6625916610133735, 'colsample_bytree': 0.864803089169032, 'gamma': 3.1877873567760657, 'reg_alpha': 4.436063712881633, 'reg_lambda': 4.7749277591032975}\n",
    "Best Score for Top 50,000: 0.829559748427673\n",
    "'''\n",
    "# There was a problem with the parameters verbosity, I had to set manually a value in range in main xgboost configuration\n",
    "xgb.set_config(verbosity=0)\n",
    "config = xgb.get_config()\n",
    "assert config['verbosity'] == 0\n",
    "xgboost.config_context(verbosity=0)\n",
    "scale_pos_weight = len(y[y == 0]) / len(y[y == 1])\n",
    "xgb_params = {\n",
    "    'n_estimators': 661,\n",
    "    'learning_rate': 0.036491004518573594,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 4,\n",
    "    'subsample': 0.6625916610133735,\n",
    "    'colsample_bytree': 0.864803089169032,\n",
    "    'gamma': 3.1877873567760657,\n",
    "    'reg_alpha': 4.436063712881633,\n",
    "    'reg_lambda': 4.7749277591032975,\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "}\n",
    "\n",
    "best_xgb_classifier = xgb.XGBClassifier(verbosity=0, **xgb_params)\n",
    "\n",
    "best_xgb_classifier.fit(X_train_final, y_train_final)\n",
    "xgb_predictions = best_xgb_classifier.predict_proba(X_test_final)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6633804\ttotal: 714ms\tremaining: 5m 46s\n",
      "1:\tlearn: 0.6394381\ttotal: 1.31s\tremaining: 5m 18s\n",
      "2:\tlearn: 0.6182192\ttotal: 1.83s\tremaining: 4m 55s\n",
      "3:\tlearn: 0.5990031\ttotal: 2.34s\tremaining: 4m 42s\n",
      "4:\tlearn: 0.5832813\ttotal: 2.79s\tremaining: 4m 28s\n",
      "5:\tlearn: 0.5696593\ttotal: 3.37s\tremaining: 4m 29s\n",
      "6:\tlearn: 0.5572461\ttotal: 3.97s\tremaining: 4m 31s\n",
      "7:\tlearn: 0.5457160\ttotal: 4.42s\tremaining: 4m 23s\n",
      "8:\tlearn: 0.5371766\ttotal: 4.97s\tremaining: 4m 23s\n",
      "9:\tlearn: 0.5294709\ttotal: 5.5s\tremaining: 4m 21s\n",
      "10:\tlearn: 0.5212493\ttotal: 6.25s\tremaining: 4m 29s\n",
      "11:\tlearn: 0.5127680\ttotal: 6.88s\tremaining: 4m 31s\n",
      "12:\tlearn: 0.5044516\ttotal: 7.5s\tremaining: 4m 32s\n",
      "13:\tlearn: 0.4982165\ttotal: 7.94s\tremaining: 4m 27s\n",
      "14:\tlearn: 0.4925573\ttotal: 8.48s\tremaining: 4m 26s\n",
      "15:\tlearn: 0.4882312\ttotal: 9.18s\tremaining: 4m 29s\n",
      "16:\tlearn: 0.4838150\ttotal: 9.68s\tremaining: 4m 27s\n",
      "17:\tlearn: 0.4782039\ttotal: 10.2s\tremaining: 4m 25s\n",
      "18:\tlearn: 0.4739136\ttotal: 10.6s\tremaining: 4m 20s\n",
      "19:\tlearn: 0.4697709\ttotal: 11s\tremaining: 4m 16s\n",
      "20:\tlearn: 0.4666750\ttotal: 11.4s\tremaining: 4m 11s\n",
      "21:\tlearn: 0.4626042\ttotal: 11.8s\tremaining: 4m 9s\n",
      "22:\tlearn: 0.4601693\ttotal: 12.2s\tremaining: 4m 5s\n",
      "23:\tlearn: 0.4573302\ttotal: 12.7s\tremaining: 4m 3s\n",
      "24:\tlearn: 0.4544267\ttotal: 13.1s\tremaining: 4m\n",
      "25:\tlearn: 0.4516707\ttotal: 13.5s\tremaining: 3m 58s\n",
      "26:\tlearn: 0.4494799\ttotal: 13.8s\tremaining: 3m 54s\n",
      "27:\tlearn: 0.4466932\ttotal: 14.2s\tremaining: 3m 52s\n",
      "28:\tlearn: 0.4437455\ttotal: 14.5s\tremaining: 3m 48s\n",
      "29:\tlearn: 0.4418021\ttotal: 14.8s\tremaining: 3m 45s\n",
      "30:\tlearn: 0.4394398\ttotal: 15.2s\tremaining: 3m 43s\n",
      "31:\tlearn: 0.4374043\ttotal: 15.9s\tremaining: 3m 45s\n",
      "32:\tlearn: 0.4357098\ttotal: 16.6s\tremaining: 3m 47s\n",
      "33:\tlearn: 0.4340527\ttotal: 17.1s\tremaining: 3m 47s\n",
      "34:\tlearn: 0.4316958\ttotal: 17.7s\tremaining: 3m 47s\n",
      "35:\tlearn: 0.4296687\ttotal: 18.2s\tremaining: 3m 47s\n",
      "36:\tlearn: 0.4276134\ttotal: 18.8s\tremaining: 3m 47s\n",
      "37:\tlearn: 0.4259492\ttotal: 19.3s\tremaining: 3m 47s\n",
      "38:\tlearn: 0.4241727\ttotal: 19.8s\tremaining: 3m 47s\n",
      "39:\tlearn: 0.4227188\ttotal: 20.3s\tremaining: 3m 46s\n",
      "40:\tlearn: 0.4209624\ttotal: 21s\tremaining: 3m 47s\n",
      "41:\tlearn: 0.4193314\ttotal: 21.4s\tremaining: 3m 46s\n",
      "42:\tlearn: 0.4174979\ttotal: 21.9s\tremaining: 3m 45s\n",
      "43:\tlearn: 0.4162722\ttotal: 22.4s\tremaining: 3m 45s\n",
      "44:\tlearn: 0.4153294\ttotal: 22.9s\tremaining: 3m 44s\n",
      "45:\tlearn: 0.4139245\ttotal: 23.3s\tremaining: 3m 43s\n",
      "46:\tlearn: 0.4126106\ttotal: 24s\tremaining: 3m 43s\n",
      "47:\tlearn: 0.4115162\ttotal: 24.5s\tremaining: 3m 43s\n",
      "48:\tlearn: 0.4103591\ttotal: 25.1s\tremaining: 3m 43s\n",
      "49:\tlearn: 0.4092843\ttotal: 25.7s\tremaining: 3m 44s\n",
      "50:\tlearn: 0.4079746\ttotal: 26.2s\tremaining: 3m 43s\n",
      "51:\tlearn: 0.4068027\ttotal: 26.8s\tremaining: 3m 43s\n",
      "52:\tlearn: 0.4058055\ttotal: 27.2s\tremaining: 3m 42s\n",
      "53:\tlearn: 0.4048115\ttotal: 27.7s\tremaining: 3m 41s\n",
      "54:\tlearn: 0.4035177\ttotal: 28s\tremaining: 3m 39s\n",
      "55:\tlearn: 0.4025391\ttotal: 28.5s\tremaining: 3m 38s\n",
      "56:\tlearn: 0.4009805\ttotal: 28.8s\tremaining: 3m 36s\n",
      "57:\tlearn: 0.3998216\ttotal: 29.2s\tremaining: 3m 35s\n",
      "58:\tlearn: 0.3988419\ttotal: 29.5s\tremaining: 3m 33s\n",
      "59:\tlearn: 0.3978335\ttotal: 29.9s\tremaining: 3m 32s\n",
      "60:\tlearn: 0.3970076\ttotal: 30.3s\tremaining: 3m 30s\n",
      "61:\tlearn: 0.3960353\ttotal: 30.6s\tremaining: 3m 29s\n",
      "62:\tlearn: 0.3952658\ttotal: 31.1s\tremaining: 3m 28s\n",
      "63:\tlearn: 0.3945659\ttotal: 31.4s\tremaining: 3m 27s\n",
      "64:\tlearn: 0.3934971\ttotal: 31.9s\tremaining: 3m 26s\n",
      "65:\tlearn: 0.3931143\ttotal: 32.5s\tremaining: 3m 27s\n",
      "66:\tlearn: 0.3923348\ttotal: 33.1s\tremaining: 3m 26s\n",
      "67:\tlearn: 0.3914841\ttotal: 33.7s\tremaining: 3m 26s\n",
      "68:\tlearn: 0.3908070\ttotal: 34.3s\tremaining: 3m 27s\n",
      "69:\tlearn: 0.3900237\ttotal: 34.8s\tremaining: 3m 27s\n",
      "70:\tlearn: 0.3893030\ttotal: 35.4s\tremaining: 3m 26s\n",
      "71:\tlearn: 0.3885783\ttotal: 36.2s\tremaining: 3m 28s\n",
      "72:\tlearn: 0.3879481\ttotal: 36.7s\tremaining: 3m 27s\n",
      "73:\tlearn: 0.3872747\ttotal: 37.3s\tremaining: 3m 27s\n",
      "74:\tlearn: 0.3867213\ttotal: 37.9s\tremaining: 3m 27s\n",
      "75:\tlearn: 0.3862076\ttotal: 38.5s\tremaining: 3m 27s\n",
      "76:\tlearn: 0.3851563\ttotal: 39s\tremaining: 3m 27s\n",
      "77:\tlearn: 0.3844183\ttotal: 39.5s\tremaining: 3m 26s\n",
      "78:\tlearn: 0.3838467\ttotal: 40.2s\tremaining: 3m 27s\n",
      "79:\tlearn: 0.3829760\ttotal: 40.9s\tremaining: 3m 27s\n",
      "80:\tlearn: 0.3819274\ttotal: 41.5s\tremaining: 3m 27s\n",
      "81:\tlearn: 0.3812739\ttotal: 42.1s\tremaining: 3m 27s\n",
      "82:\tlearn: 0.3809552\ttotal: 42.8s\tremaining: 3m 27s\n",
      "83:\tlearn: 0.3800975\ttotal: 43.5s\tremaining: 3m 28s\n",
      "84:\tlearn: 0.3794288\ttotal: 44s\tremaining: 3m 27s\n",
      "85:\tlearn: 0.3787053\ttotal: 44.7s\tremaining: 3m 27s\n",
      "86:\tlearn: 0.3782239\ttotal: 45.2s\tremaining: 3m 27s\n",
      "87:\tlearn: 0.3776586\ttotal: 45.7s\tremaining: 3m 26s\n",
      "88:\tlearn: 0.3772436\ttotal: 46.3s\tremaining: 3m 26s\n",
      "89:\tlearn: 0.3766682\ttotal: 46.9s\tremaining: 3m 26s\n",
      "90:\tlearn: 0.3762194\ttotal: 47.4s\tremaining: 3m 25s\n",
      "91:\tlearn: 0.3757463\ttotal: 48s\tremaining: 3m 25s\n",
      "92:\tlearn: 0.3754067\ttotal: 48.4s\tremaining: 3m 24s\n",
      "93:\tlearn: 0.3745817\ttotal: 49s\tremaining: 3m 24s\n",
      "94:\tlearn: 0.3742085\ttotal: 49.4s\tremaining: 3m 23s\n",
      "95:\tlearn: 0.3735940\ttotal: 49.9s\tremaining: 3m 22s\n",
      "96:\tlearn: 0.3730393\ttotal: 50.4s\tremaining: 3m 22s\n",
      "97:\tlearn: 0.3724254\ttotal: 51s\tremaining: 3m 21s\n",
      "98:\tlearn: 0.3721207\ttotal: 51.6s\tremaining: 3m 21s\n",
      "99:\tlearn: 0.3712814\ttotal: 52.1s\tremaining: 3m 20s\n",
      "100:\tlearn: 0.3709458\ttotal: 52.6s\tremaining: 3m 20s\n",
      "101:\tlearn: 0.3706301\ttotal: 53.1s\tremaining: 3m 19s\n",
      "102:\tlearn: 0.3702320\ttotal: 53.5s\tremaining: 3m 18s\n",
      "103:\tlearn: 0.3695487\ttotal: 53.9s\tremaining: 3m 18s\n",
      "104:\tlearn: 0.3691445\ttotal: 54.6s\tremaining: 3m 18s\n",
      "105:\tlearn: 0.3683868\ttotal: 55.2s\tremaining: 3m 17s\n",
      "106:\tlearn: 0.3680044\ttotal: 56.1s\tremaining: 3m 18s\n",
      "107:\tlearn: 0.3675789\ttotal: 56.7s\tremaining: 3m 18s\n",
      "108:\tlearn: 0.3672909\ttotal: 57.2s\tremaining: 3m 17s\n",
      "109:\tlearn: 0.3668758\ttotal: 58s\tremaining: 3m 18s\n",
      "110:\tlearn: 0.3665708\ttotal: 58.8s\tremaining: 3m 18s\n",
      "111:\tlearn: 0.3661965\ttotal: 59.5s\tremaining: 3m 18s\n",
      "112:\tlearn: 0.3656379\ttotal: 1m\tremaining: 3m 18s\n",
      "113:\tlearn: 0.3651325\ttotal: 1m\tremaining: 3m 18s\n",
      "114:\tlearn: 0.3647153\ttotal: 1m 1s\tremaining: 3m 17s\n",
      "115:\tlearn: 0.3642208\ttotal: 1m 1s\tremaining: 3m 16s\n",
      "116:\tlearn: 0.3637314\ttotal: 1m 2s\tremaining: 3m 16s\n",
      "117:\tlearn: 0.3631231\ttotal: 1m 2s\tremaining: 3m 15s\n",
      "118:\tlearn: 0.3627156\ttotal: 1m 3s\tremaining: 3m 15s\n",
      "119:\tlearn: 0.3623520\ttotal: 1m 3s\tremaining: 3m 14s\n",
      "120:\tlearn: 0.3619432\ttotal: 1m 4s\tremaining: 3m 14s\n",
      "121:\tlearn: 0.3615155\ttotal: 1m 5s\tremaining: 3m 14s\n",
      "122:\tlearn: 0.3610724\ttotal: 1m 5s\tremaining: 3m 13s\n",
      "123:\tlearn: 0.3606521\ttotal: 1m 6s\tremaining: 3m 13s\n",
      "124:\tlearn: 0.3602581\ttotal: 1m 6s\tremaining: 3m 12s\n",
      "125:\tlearn: 0.3600179\ttotal: 1m 7s\tremaining: 3m 12s\n",
      "126:\tlearn: 0.3594945\ttotal: 1m 7s\tremaining: 3m 11s\n",
      "127:\tlearn: 0.3592116\ttotal: 1m 8s\tremaining: 3m 11s\n",
      "128:\tlearn: 0.3589351\ttotal: 1m 8s\tremaining: 3m 10s\n",
      "129:\tlearn: 0.3585858\ttotal: 1m 9s\tremaining: 3m 10s\n",
      "130:\tlearn: 0.3582668\ttotal: 1m 10s\tremaining: 3m 9s\n",
      "131:\tlearn: 0.3578213\ttotal: 1m 10s\tremaining: 3m 9s\n",
      "132:\tlearn: 0.3573353\ttotal: 1m 11s\tremaining: 3m 8s\n",
      "133:\tlearn: 0.3570362\ttotal: 1m 11s\tremaining: 3m 8s\n",
      "134:\tlearn: 0.3566600\ttotal: 1m 12s\tremaining: 3m 7s\n",
      "135:\tlearn: 0.3561986\ttotal: 1m 12s\tremaining: 3m 7s\n",
      "136:\tlearn: 0.3557882\ttotal: 1m 13s\tremaining: 3m 6s\n",
      "137:\tlearn: 0.3553613\ttotal: 1m 13s\tremaining: 3m 6s\n",
      "138:\tlearn: 0.3547947\ttotal: 1m 15s\tremaining: 3m 7s\n",
      "139:\tlearn: 0.3543601\ttotal: 1m 15s\tremaining: 3m 7s\n",
      "140:\tlearn: 0.3537523\ttotal: 1m 16s\tremaining: 3m 7s\n",
      "141:\tlearn: 0.3534033\ttotal: 1m 17s\tremaining: 3m 7s\n",
      "142:\tlearn: 0.3528025\ttotal: 1m 17s\tremaining: 3m 6s\n",
      "143:\tlearn: 0.3522545\ttotal: 1m 18s\tremaining: 3m 6s\n",
      "144:\tlearn: 0.3518936\ttotal: 1m 18s\tremaining: 3m 5s\n",
      "145:\tlearn: 0.3512929\ttotal: 1m 19s\tremaining: 3m 5s\n",
      "146:\tlearn: 0.3510010\ttotal: 1m 20s\tremaining: 3m 4s\n",
      "147:\tlearn: 0.3506109\ttotal: 1m 20s\tremaining: 3m 3s\n",
      "148:\tlearn: 0.3502911\ttotal: 1m 21s\tremaining: 3m 3s\n",
      "149:\tlearn: 0.3499593\ttotal: 1m 21s\tremaining: 3m 3s\n",
      "150:\tlearn: 0.3495070\ttotal: 1m 22s\tremaining: 3m 2s\n",
      "151:\tlearn: 0.3491297\ttotal: 1m 22s\tremaining: 3m 2s\n",
      "152:\tlearn: 0.3487635\ttotal: 1m 23s\tremaining: 3m 1s\n",
      "153:\tlearn: 0.3485226\ttotal: 1m 23s\tremaining: 3m 1s\n",
      "154:\tlearn: 0.3480195\ttotal: 1m 24s\tremaining: 3m\n",
      "155:\tlearn: 0.3477854\ttotal: 1m 25s\tremaining: 3m\n",
      "156:\tlearn: 0.3472946\ttotal: 1m 25s\tremaining: 2m 59s\n",
      "157:\tlearn: 0.3468464\ttotal: 1m 26s\tremaining: 2m 59s\n",
      "158:\tlearn: 0.3461219\ttotal: 1m 27s\tremaining: 2m 59s\n",
      "159:\tlearn: 0.3455988\ttotal: 1m 27s\tremaining: 2m 58s\n",
      "160:\tlearn: 0.3451706\ttotal: 1m 28s\tremaining: 2m 57s\n",
      "161:\tlearn: 0.3446898\ttotal: 1m 28s\tremaining: 2m 57s\n",
      "162:\tlearn: 0.3442306\ttotal: 1m 29s\tremaining: 2m 57s\n",
      "163:\tlearn: 0.3439264\ttotal: 1m 30s\tremaining: 2m 56s\n",
      "164:\tlearn: 0.3433335\ttotal: 1m 30s\tremaining: 2m 56s\n",
      "165:\tlearn: 0.3430090\ttotal: 1m 31s\tremaining: 2m 55s\n",
      "166:\tlearn: 0.3425188\ttotal: 1m 31s\tremaining: 2m 54s\n",
      "167:\tlearn: 0.3423302\ttotal: 1m 32s\tremaining: 2m 54s\n",
      "168:\tlearn: 0.3418177\ttotal: 1m 32s\tremaining: 2m 54s\n",
      "169:\tlearn: 0.3414295\ttotal: 1m 33s\tremaining: 2m 54s\n",
      "170:\tlearn: 0.3410501\ttotal: 1m 34s\tremaining: 2m 53s\n",
      "171:\tlearn: 0.3406091\ttotal: 1m 34s\tremaining: 2m 53s\n",
      "172:\tlearn: 0.3402132\ttotal: 1m 35s\tremaining: 2m 52s\n",
      "173:\tlearn: 0.3398071\ttotal: 1m 35s\tremaining: 2m 52s\n",
      "174:\tlearn: 0.3393321\ttotal: 1m 36s\tremaining: 2m 51s\n",
      "175:\tlearn: 0.3388795\ttotal: 1m 37s\tremaining: 2m 51s\n",
      "176:\tlearn: 0.3382075\ttotal: 1m 37s\tremaining: 2m 50s\n",
      "177:\tlearn: 0.3376264\ttotal: 1m 38s\tremaining: 2m 49s\n",
      "178:\tlearn: 0.3372228\ttotal: 1m 38s\tremaining: 2m 49s\n",
      "179:\tlearn: 0.3367882\ttotal: 1m 39s\tremaining: 2m 48s\n",
      "180:\tlearn: 0.3363468\ttotal: 1m 39s\tremaining: 2m 47s\n",
      "181:\tlearn: 0.3360689\ttotal: 1m 40s\tremaining: 2m 47s\n",
      "182:\tlearn: 0.3356191\ttotal: 1m 40s\tremaining: 2m 46s\n",
      "183:\tlearn: 0.3352911\ttotal: 1m 41s\tremaining: 2m 46s\n",
      "184:\tlearn: 0.3348005\ttotal: 1m 41s\tremaining: 2m 45s\n",
      "185:\tlearn: 0.3343608\ttotal: 1m 42s\tremaining: 2m 45s\n",
      "186:\tlearn: 0.3340214\ttotal: 1m 42s\tremaining: 2m 44s\n",
      "187:\tlearn: 0.3336913\ttotal: 1m 43s\tremaining: 2m 44s\n",
      "188:\tlearn: 0.3331203\ttotal: 1m 44s\tremaining: 2m 43s\n",
      "189:\tlearn: 0.3327242\ttotal: 1m 44s\tremaining: 2m 43s\n",
      "190:\tlearn: 0.3322750\ttotal: 1m 45s\tremaining: 2m 42s\n",
      "191:\tlearn: 0.3318260\ttotal: 1m 45s\tremaining: 2m 41s\n",
      "192:\tlearn: 0.3312034\ttotal: 1m 46s\tremaining: 2m 41s\n",
      "193:\tlearn: 0.3307489\ttotal: 1m 47s\tremaining: 2m 41s\n",
      "194:\tlearn: 0.3304781\ttotal: 1m 47s\tremaining: 2m 40s\n",
      "195:\tlearn: 0.3301119\ttotal: 1m 48s\tremaining: 2m 39s\n",
      "196:\tlearn: 0.3297908\ttotal: 1m 48s\tremaining: 2m 39s\n",
      "197:\tlearn: 0.3294336\ttotal: 1m 49s\tremaining: 2m 38s\n",
      "198:\tlearn: 0.3290482\ttotal: 1m 49s\tremaining: 2m 38s\n",
      "199:\tlearn: 0.3287656\ttotal: 1m 50s\tremaining: 2m 37s\n",
      "200:\tlearn: 0.3283440\ttotal: 1m 50s\tremaining: 2m 37s\n",
      "201:\tlearn: 0.3280373\ttotal: 1m 51s\tremaining: 2m 36s\n",
      "202:\tlearn: 0.3275969\ttotal: 1m 51s\tremaining: 2m 36s\n",
      "203:\tlearn: 0.3272654\ttotal: 1m 52s\tremaining: 2m 35s\n",
      "204:\tlearn: 0.3268865\ttotal: 1m 53s\tremaining: 2m 35s\n",
      "205:\tlearn: 0.3265337\ttotal: 1m 53s\tremaining: 2m 34s\n",
      "206:\tlearn: 0.3262373\ttotal: 1m 54s\tremaining: 2m 34s\n",
      "207:\tlearn: 0.3260179\ttotal: 1m 55s\tremaining: 2m 33s\n",
      "208:\tlearn: 0.3255750\ttotal: 1m 55s\tremaining: 2m 33s\n",
      "209:\tlearn: 0.3252185\ttotal: 1m 56s\tremaining: 2m 32s\n",
      "210:\tlearn: 0.3248661\ttotal: 1m 56s\tremaining: 2m 32s\n",
      "211:\tlearn: 0.3244788\ttotal: 1m 57s\tremaining: 2m 31s\n",
      "212:\tlearn: 0.3241644\ttotal: 1m 58s\tremaining: 2m 31s\n",
      "213:\tlearn: 0.3238656\ttotal: 1m 58s\tremaining: 2m 30s\n",
      "214:\tlearn: 0.3235489\ttotal: 1m 59s\tremaining: 2m 30s\n",
      "215:\tlearn: 0.3231798\ttotal: 1m 59s\tremaining: 2m 29s\n",
      "216:\tlearn: 0.3228735\ttotal: 2m\tremaining: 2m 29s\n",
      "217:\tlearn: 0.3225933\ttotal: 2m 1s\tremaining: 2m 28s\n",
      "218:\tlearn: 0.3222408\ttotal: 2m 1s\tremaining: 2m 28s\n",
      "219:\tlearn: 0.3218702\ttotal: 2m 2s\tremaining: 2m 27s\n",
      "220:\tlearn: 0.3216455\ttotal: 2m 2s\tremaining: 2m 27s\n",
      "221:\tlearn: 0.3214226\ttotal: 2m 3s\tremaining: 2m 26s\n",
      "222:\tlearn: 0.3211037\ttotal: 2m 3s\tremaining: 2m 26s\n",
      "223:\tlearn: 0.3208494\ttotal: 2m 4s\tremaining: 2m 25s\n",
      "224:\tlearn: 0.3205357\ttotal: 2m 5s\tremaining: 2m 25s\n",
      "225:\tlearn: 0.3202232\ttotal: 2m 5s\tremaining: 2m 24s\n",
      "226:\tlearn: 0.3198137\ttotal: 2m 6s\tremaining: 2m 24s\n",
      "227:\tlearn: 0.3194663\ttotal: 2m 7s\tremaining: 2m 24s\n",
      "228:\tlearn: 0.3190810\ttotal: 2m 7s\tremaining: 2m 23s\n",
      "229:\tlearn: 0.3187945\ttotal: 2m 8s\tremaining: 2m 23s\n",
      "230:\tlearn: 0.3184481\ttotal: 2m 9s\tremaining: 2m 22s\n",
      "231:\tlearn: 0.3180767\ttotal: 2m 9s\tremaining: 2m 22s\n",
      "232:\tlearn: 0.3177934\ttotal: 2m 10s\tremaining: 2m 21s\n",
      "233:\tlearn: 0.3174447\ttotal: 2m 10s\tremaining: 2m 20s\n",
      "234:\tlearn: 0.3171726\ttotal: 2m 11s\tremaining: 2m 20s\n",
      "235:\tlearn: 0.3168921\ttotal: 2m 12s\tremaining: 2m 19s\n",
      "236:\tlearn: 0.3166939\ttotal: 2m 12s\tremaining: 2m 19s\n",
      "237:\tlearn: 0.3163725\ttotal: 2m 13s\tremaining: 2m 18s\n",
      "238:\tlearn: 0.3161157\ttotal: 2m 13s\tremaining: 2m 18s\n",
      "239:\tlearn: 0.3157830\ttotal: 2m 14s\tremaining: 2m 17s\n",
      "240:\tlearn: 0.3153901\ttotal: 2m 15s\tremaining: 2m 17s\n",
      "241:\tlearn: 0.3151189\ttotal: 2m 15s\tremaining: 2m 16s\n",
      "242:\tlearn: 0.3148757\ttotal: 2m 16s\tremaining: 2m 16s\n",
      "243:\tlearn: 0.3146034\ttotal: 2m 16s\tremaining: 2m 15s\n",
      "244:\tlearn: 0.3144128\ttotal: 2m 17s\tremaining: 2m 15s\n",
      "245:\tlearn: 0.3140916\ttotal: 2m 18s\tremaining: 2m 14s\n",
      "246:\tlearn: 0.3137255\ttotal: 2m 18s\tremaining: 2m 14s\n",
      "247:\tlearn: 0.3134355\ttotal: 2m 19s\tremaining: 2m 13s\n",
      "248:\tlearn: 0.3131023\ttotal: 2m 20s\tremaining: 2m 13s\n",
      "249:\tlearn: 0.3127695\ttotal: 2m 20s\tremaining: 2m 12s\n",
      "250:\tlearn: 0.3124567\ttotal: 2m 21s\tremaining: 2m 12s\n",
      "251:\tlearn: 0.3121665\ttotal: 2m 22s\tremaining: 2m 11s\n",
      "252:\tlearn: 0.3118486\ttotal: 2m 22s\tremaining: 2m 11s\n",
      "253:\tlearn: 0.3115135\ttotal: 2m 23s\tremaining: 2m 10s\n",
      "254:\tlearn: 0.3111737\ttotal: 2m 23s\tremaining: 2m 10s\n",
      "255:\tlearn: 0.3109070\ttotal: 2m 24s\tremaining: 2m 9s\n",
      "256:\tlearn: 0.3105415\ttotal: 2m 24s\tremaining: 2m 9s\n",
      "257:\tlearn: 0.3102399\ttotal: 2m 25s\tremaining: 2m 8s\n",
      "258:\tlearn: 0.3098921\ttotal: 2m 26s\tremaining: 2m 8s\n",
      "259:\tlearn: 0.3096202\ttotal: 2m 27s\tremaining: 2m 7s\n",
      "260:\tlearn: 0.3094149\ttotal: 2m 27s\tremaining: 2m 7s\n",
      "261:\tlearn: 0.3091971\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "262:\tlearn: 0.3088832\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "263:\tlearn: 0.3084912\ttotal: 2m 29s\tremaining: 2m 5s\n",
      "264:\tlearn: 0.3081609\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "265:\tlearn: 0.3079877\ttotal: 2m 30s\tremaining: 2m 4s\n",
      "266:\tlearn: 0.3076893\ttotal: 2m 31s\tremaining: 2m 4s\n",
      "267:\tlearn: 0.3074854\ttotal: 2m 32s\tremaining: 2m 3s\n",
      "268:\tlearn: 0.3071788\ttotal: 2m 33s\tremaining: 2m 3s\n",
      "269:\tlearn: 0.3068861\ttotal: 2m 34s\tremaining: 2m 3s\n",
      "270:\tlearn: 0.3065605\ttotal: 2m 34s\tremaining: 2m 2s\n",
      "271:\tlearn: 0.3062301\ttotal: 2m 35s\tremaining: 2m 2s\n",
      "272:\tlearn: 0.3060405\ttotal: 2m 35s\tremaining: 2m 1s\n",
      "273:\tlearn: 0.3058740\ttotal: 2m 36s\tremaining: 2m 1s\n",
      "274:\tlearn: 0.3057229\ttotal: 2m 37s\tremaining: 2m\n",
      "275:\tlearn: 0.3053436\ttotal: 2m 37s\tremaining: 2m\n",
      "276:\tlearn: 0.3051029\ttotal: 2m 38s\tremaining: 1m 59s\n",
      "277:\tlearn: 0.3048685\ttotal: 2m 38s\tremaining: 1m 58s\n",
      "278:\tlearn: 0.3045979\ttotal: 2m 39s\tremaining: 1m 58s\n",
      "279:\tlearn: 0.3043451\ttotal: 2m 40s\tremaining: 1m 57s\n",
      "280:\tlearn: 0.3041543\ttotal: 2m 40s\tremaining: 1m 57s\n",
      "281:\tlearn: 0.3038420\ttotal: 2m 41s\tremaining: 1m 56s\n",
      "282:\tlearn: 0.3035042\ttotal: 2m 41s\tremaining: 1m 56s\n",
      "283:\tlearn: 0.3031898\ttotal: 2m 42s\tremaining: 1m 55s\n",
      "284:\tlearn: 0.3029958\ttotal: 2m 43s\tremaining: 1m 55s\n",
      "285:\tlearn: 0.3027304\ttotal: 2m 43s\tremaining: 1m 54s\n",
      "286:\tlearn: 0.3024449\ttotal: 2m 44s\tremaining: 1m 54s\n",
      "287:\tlearn: 0.3022098\ttotal: 2m 45s\tremaining: 1m 53s\n",
      "288:\tlearn: 0.3019304\ttotal: 2m 45s\tremaining: 1m 52s\n",
      "289:\tlearn: 0.3017148\ttotal: 2m 46s\tremaining: 1m 52s\n",
      "290:\tlearn: 0.3014469\ttotal: 2m 46s\tremaining: 1m 51s\n",
      "291:\tlearn: 0.3011504\ttotal: 2m 47s\tremaining: 1m 51s\n",
      "292:\tlearn: 0.3009084\ttotal: 2m 48s\tremaining: 1m 50s\n",
      "293:\tlearn: 0.3006434\ttotal: 2m 48s\tremaining: 1m 50s\n",
      "294:\tlearn: 0.3004400\ttotal: 2m 49s\tremaining: 1m 49s\n",
      "295:\tlearn: 0.3002668\ttotal: 2m 49s\tremaining: 1m 48s\n",
      "296:\tlearn: 0.2999791\ttotal: 2m 50s\tremaining: 1m 48s\n",
      "297:\tlearn: 0.2997145\ttotal: 2m 50s\tremaining: 1m 47s\n",
      "298:\tlearn: 0.2995330\ttotal: 2m 51s\tremaining: 1m 47s\n",
      "299:\tlearn: 0.2992198\ttotal: 2m 51s\tremaining: 1m 46s\n",
      "300:\tlearn: 0.2989641\ttotal: 2m 52s\tremaining: 1m 46s\n",
      "301:\tlearn: 0.2988223\ttotal: 2m 53s\tremaining: 1m 45s\n",
      "302:\tlearn: 0.2984494\ttotal: 2m 54s\tremaining: 1m 45s\n",
      "303:\tlearn: 0.2982024\ttotal: 2m 54s\tremaining: 1m 44s\n",
      "304:\tlearn: 0.2980335\ttotal: 2m 55s\tremaining: 1m 43s\n",
      "305:\tlearn: 0.2977289\ttotal: 2m 55s\tremaining: 1m 43s\n",
      "306:\tlearn: 0.2974290\ttotal: 2m 56s\tremaining: 1m 42s\n",
      "307:\tlearn: 0.2973015\ttotal: 2m 57s\tremaining: 1m 42s\n",
      "308:\tlearn: 0.2970838\ttotal: 2m 57s\tremaining: 1m 41s\n",
      "309:\tlearn: 0.2968209\ttotal: 2m 58s\tremaining: 1m 41s\n",
      "310:\tlearn: 0.2965664\ttotal: 2m 59s\tremaining: 1m 40s\n",
      "311:\tlearn: 0.2961917\ttotal: 2m 59s\tremaining: 1m 40s\n",
      "312:\tlearn: 0.2959181\ttotal: 3m\tremaining: 1m 39s\n",
      "313:\tlearn: 0.2957535\ttotal: 3m\tremaining: 1m 39s\n",
      "314:\tlearn: 0.2956138\ttotal: 3m 1s\tremaining: 1m 38s\n",
      "315:\tlearn: 0.2953129\ttotal: 3m 2s\tremaining: 1m 38s\n",
      "316:\tlearn: 0.2950247\ttotal: 3m 2s\tremaining: 1m 37s\n",
      "317:\tlearn: 0.2948075\ttotal: 3m 3s\tremaining: 1m 36s\n",
      "318:\tlearn: 0.2946353\ttotal: 3m 4s\tremaining: 1m 36s\n",
      "319:\tlearn: 0.2944290\ttotal: 3m 4s\tremaining: 1m 35s\n",
      "320:\tlearn: 0.2942320\ttotal: 3m 5s\tremaining: 1m 35s\n",
      "321:\tlearn: 0.2940066\ttotal: 3m 5s\tremaining: 1m 34s\n",
      "322:\tlearn: 0.2937993\ttotal: 3m 6s\tremaining: 1m 34s\n",
      "323:\tlearn: 0.2935823\ttotal: 3m 6s\tremaining: 1m 33s\n",
      "324:\tlearn: 0.2934509\ttotal: 3m 7s\tremaining: 1m 32s\n",
      "325:\tlearn: 0.2931880\ttotal: 3m 8s\tremaining: 1m 32s\n",
      "326:\tlearn: 0.2929041\ttotal: 3m 8s\tremaining: 1m 31s\n",
      "327:\tlearn: 0.2926885\ttotal: 3m 9s\tremaining: 1m 31s\n",
      "328:\tlearn: 0.2925090\ttotal: 3m 9s\tremaining: 1m 30s\n",
      "329:\tlearn: 0.2922956\ttotal: 3m 10s\tremaining: 1m 30s\n",
      "330:\tlearn: 0.2921135\ttotal: 3m 10s\tremaining: 1m 29s\n",
      "331:\tlearn: 0.2918436\ttotal: 3m 11s\tremaining: 1m 28s\n",
      "332:\tlearn: 0.2916787\ttotal: 3m 11s\tremaining: 1m 28s\n",
      "333:\tlearn: 0.2914906\ttotal: 3m 12s\tremaining: 1m 27s\n",
      "334:\tlearn: 0.2913028\ttotal: 3m 13s\tremaining: 1m 27s\n",
      "335:\tlearn: 0.2910430\ttotal: 3m 13s\tremaining: 1m 26s\n",
      "336:\tlearn: 0.2908163\ttotal: 3m 14s\tremaining: 1m 25s\n",
      "337:\tlearn: 0.2906013\ttotal: 3m 14s\tremaining: 1m 25s\n",
      "338:\tlearn: 0.2903591\ttotal: 3m 15s\tremaining: 1m 24s\n",
      "339:\tlearn: 0.2902033\ttotal: 3m 15s\tremaining: 1m 24s\n",
      "340:\tlearn: 0.2899395\ttotal: 3m 16s\tremaining: 1m 23s\n",
      "341:\tlearn: 0.2897460\ttotal: 3m 17s\tremaining: 1m 23s\n",
      "342:\tlearn: 0.2896067\ttotal: 3m 18s\tremaining: 1m 22s\n",
      "343:\tlearn: 0.2894202\ttotal: 3m 18s\tremaining: 1m 22s\n",
      "344:\tlearn: 0.2892720\ttotal: 3m 19s\tremaining: 1m 21s\n",
      "345:\tlearn: 0.2890979\ttotal: 3m 19s\tremaining: 1m 20s\n",
      "346:\tlearn: 0.2889693\ttotal: 3m 20s\tremaining: 1m 20s\n",
      "347:\tlearn: 0.2886959\ttotal: 3m 20s\tremaining: 1m 19s\n",
      "348:\tlearn: 0.2884644\ttotal: 3m 21s\tremaining: 1m 19s\n",
      "349:\tlearn: 0.2882346\ttotal: 3m 22s\tremaining: 1m 18s\n",
      "350:\tlearn: 0.2880173\ttotal: 3m 22s\tremaining: 1m 17s\n",
      "351:\tlearn: 0.2878163\ttotal: 3m 23s\tremaining: 1m 17s\n",
      "352:\tlearn: 0.2876389\ttotal: 3m 23s\tremaining: 1m 16s\n",
      "353:\tlearn: 0.2874433\ttotal: 3m 24s\tremaining: 1m 16s\n",
      "354:\tlearn: 0.2872586\ttotal: 3m 25s\tremaining: 1m 15s\n",
      "355:\tlearn: 0.2868900\ttotal: 3m 25s\tremaining: 1m 15s\n",
      "356:\tlearn: 0.2866525\ttotal: 3m 26s\tremaining: 1m 14s\n",
      "357:\tlearn: 0.2864333\ttotal: 3m 26s\tremaining: 1m 13s\n",
      "358:\tlearn: 0.2862224\ttotal: 3m 27s\tremaining: 1m 13s\n",
      "359:\tlearn: 0.2859918\ttotal: 3m 27s\tremaining: 1m 12s\n",
      "360:\tlearn: 0.2856802\ttotal: 3m 28s\tremaining: 1m 12s\n",
      "361:\tlearn: 0.2854556\ttotal: 3m 28s\tremaining: 1m 11s\n",
      "362:\tlearn: 0.2852733\ttotal: 3m 29s\tremaining: 1m 10s\n",
      "363:\tlearn: 0.2850463\ttotal: 3m 30s\tremaining: 1m 10s\n",
      "364:\tlearn: 0.2846800\ttotal: 3m 30s\tremaining: 1m 9s\n",
      "365:\tlearn: 0.2845175\ttotal: 3m 31s\tremaining: 1m 9s\n",
      "366:\tlearn: 0.2842792\ttotal: 3m 31s\tremaining: 1m 8s\n",
      "367:\tlearn: 0.2840233\ttotal: 3m 32s\tremaining: 1m 8s\n",
      "368:\tlearn: 0.2837691\ttotal: 3m 32s\tremaining: 1m 7s\n",
      "369:\tlearn: 0.2835724\ttotal: 3m 33s\tremaining: 1m 6s\n",
      "370:\tlearn: 0.2833093\ttotal: 3m 33s\tremaining: 1m 6s\n",
      "371:\tlearn: 0.2830659\ttotal: 3m 34s\tremaining: 1m 5s\n",
      "372:\tlearn: 0.2828534\ttotal: 3m 35s\tremaining: 1m 5s\n",
      "373:\tlearn: 0.2826146\ttotal: 3m 35s\tremaining: 1m 4s\n",
      "374:\tlearn: 0.2824137\ttotal: 3m 36s\tremaining: 1m 3s\n",
      "375:\tlearn: 0.2821821\ttotal: 3m 36s\tremaining: 1m 3s\n",
      "376:\tlearn: 0.2819456\ttotal: 3m 37s\tremaining: 1m 2s\n",
      "377:\tlearn: 0.2817707\ttotal: 3m 37s\tremaining: 1m 2s\n",
      "378:\tlearn: 0.2815435\ttotal: 3m 38s\tremaining: 1m 1s\n",
      "379:\tlearn: 0.2813380\ttotal: 3m 38s\tremaining: 1m 1s\n",
      "380:\tlearn: 0.2811729\ttotal: 3m 39s\tremaining: 1m\n",
      "381:\tlearn: 0.2809613\ttotal: 3m 40s\tremaining: 59.9s\n",
      "382:\tlearn: 0.2807888\ttotal: 3m 40s\tremaining: 59.4s\n",
      "383:\tlearn: 0.2806554\ttotal: 3m 41s\tremaining: 58.8s\n",
      "384:\tlearn: 0.2804798\ttotal: 3m 41s\tremaining: 58.2s\n",
      "385:\tlearn: 0.2802935\ttotal: 3m 42s\tremaining: 57.6s\n",
      "386:\tlearn: 0.2799494\ttotal: 3m 42s\tremaining: 57s\n",
      "387:\tlearn: 0.2796324\ttotal: 3m 43s\tremaining: 56.4s\n",
      "388:\tlearn: 0.2793657\ttotal: 3m 43s\tremaining: 55.8s\n",
      "389:\tlearn: 0.2791601\ttotal: 3m 44s\tremaining: 55.2s\n",
      "390:\tlearn: 0.2790152\ttotal: 3m 44s\tremaining: 54.7s\n",
      "391:\tlearn: 0.2787809\ttotal: 3m 45s\tremaining: 54.1s\n",
      "392:\tlearn: 0.2786266\ttotal: 3m 46s\tremaining: 53.5s\n",
      "393:\tlearn: 0.2784359\ttotal: 3m 46s\tremaining: 52.9s\n",
      "394:\tlearn: 0.2782363\ttotal: 3m 47s\tremaining: 52.4s\n",
      "395:\tlearn: 0.2779970\ttotal: 3m 47s\tremaining: 51.8s\n",
      "396:\tlearn: 0.2778426\ttotal: 3m 48s\tremaining: 51.2s\n",
      "397:\tlearn: 0.2776699\ttotal: 3m 49s\tremaining: 50.6s\n",
      "398:\tlearn: 0.2774912\ttotal: 3m 49s\tremaining: 50.1s\n",
      "399:\tlearn: 0.2772344\ttotal: 3m 50s\tremaining: 49.5s\n",
      "400:\tlearn: 0.2770595\ttotal: 3m 50s\tremaining: 48.9s\n",
      "401:\tlearn: 0.2768363\ttotal: 3m 51s\tremaining: 48.3s\n",
      "402:\tlearn: 0.2765741\ttotal: 3m 51s\tremaining: 47.7s\n",
      "403:\tlearn: 0.2763834\ttotal: 3m 52s\tremaining: 47.1s\n",
      "404:\tlearn: 0.2760962\ttotal: 3m 52s\tremaining: 46.6s\n",
      "405:\tlearn: 0.2759567\ttotal: 3m 53s\tremaining: 46s\n",
      "406:\tlearn: 0.2757858\ttotal: 3m 53s\tremaining: 45.4s\n",
      "407:\tlearn: 0.2754877\ttotal: 3m 54s\tremaining: 44.8s\n",
      "408:\tlearn: 0.2753203\ttotal: 3m 54s\tremaining: 44.2s\n",
      "409:\tlearn: 0.2749955\ttotal: 3m 55s\tremaining: 43.7s\n",
      "410:\tlearn: 0.2747487\ttotal: 3m 56s\tremaining: 43.1s\n",
      "411:\tlearn: 0.2745863\ttotal: 3m 57s\tremaining: 42.6s\n",
      "412:\tlearn: 0.2742784\ttotal: 3m 57s\tremaining: 42s\n",
      "413:\tlearn: 0.2741044\ttotal: 3m 58s\tremaining: 41.4s\n",
      "414:\tlearn: 0.2738271\ttotal: 3m 58s\tremaining: 40.9s\n",
      "415:\tlearn: 0.2736598\ttotal: 3m 59s\tremaining: 40.3s\n",
      "416:\tlearn: 0.2734001\ttotal: 4m\tremaining: 39.7s\n",
      "417:\tlearn: 0.2732149\ttotal: 4m\tremaining: 39.1s\n",
      "418:\tlearn: 0.2730253\ttotal: 4m 1s\tremaining: 38.6s\n",
      "419:\tlearn: 0.2728141\ttotal: 4m 1s\tremaining: 38s\n",
      "420:\tlearn: 0.2725547\ttotal: 4m 2s\tremaining: 37.4s\n",
      "421:\tlearn: 0.2723871\ttotal: 4m 2s\tremaining: 36.8s\n",
      "422:\tlearn: 0.2721518\ttotal: 4m 3s\tremaining: 36.2s\n",
      "423:\tlearn: 0.2719729\ttotal: 4m 3s\tremaining: 35.7s\n",
      "424:\tlearn: 0.2717774\ttotal: 4m 4s\tremaining: 35.1s\n",
      "425:\tlearn: 0.2715591\ttotal: 4m 4s\tremaining: 34.5s\n",
      "426:\tlearn: 0.2712923\ttotal: 4m 5s\tremaining: 33.9s\n",
      "427:\tlearn: 0.2710292\ttotal: 4m 5s\tremaining: 33.3s\n",
      "428:\tlearn: 0.2708777\ttotal: 4m 6s\tremaining: 32.8s\n",
      "429:\tlearn: 0.2706541\ttotal: 4m 7s\tremaining: 32.2s\n",
      "430:\tlearn: 0.2704849\ttotal: 4m 7s\tremaining: 31.6s\n",
      "431:\tlearn: 0.2703490\ttotal: 4m 8s\tremaining: 31s\n",
      "432:\tlearn: 0.2701872\ttotal: 4m 8s\tremaining: 30.5s\n",
      "433:\tlearn: 0.2700119\ttotal: 4m 9s\tremaining: 29.9s\n",
      "434:\tlearn: 0.2698443\ttotal: 4m 10s\tremaining: 29.3s\n",
      "435:\tlearn: 0.2696708\ttotal: 4m 10s\tremaining: 28.7s\n",
      "436:\tlearn: 0.2695317\ttotal: 4m 11s\tremaining: 28.2s\n",
      "437:\tlearn: 0.2693286\ttotal: 4m 11s\tremaining: 27.6s\n",
      "438:\tlearn: 0.2691818\ttotal: 4m 12s\tremaining: 27s\n",
      "439:\tlearn: 0.2690214\ttotal: 4m 13s\tremaining: 26.5s\n",
      "440:\tlearn: 0.2688673\ttotal: 4m 13s\tremaining: 25.9s\n",
      "441:\tlearn: 0.2686470\ttotal: 4m 14s\tremaining: 25.3s\n",
      "442:\tlearn: 0.2684692\ttotal: 4m 14s\tremaining: 24.7s\n",
      "443:\tlearn: 0.2682569\ttotal: 4m 15s\tremaining: 24.2s\n",
      "444:\tlearn: 0.2681368\ttotal: 4m 16s\tremaining: 23.6s\n",
      "445:\tlearn: 0.2679224\ttotal: 4m 16s\tremaining: 23s\n",
      "446:\tlearn: 0.2677672\ttotal: 4m 17s\tremaining: 22.4s\n",
      "447:\tlearn: 0.2676200\ttotal: 4m 17s\tremaining: 21.9s\n",
      "448:\tlearn: 0.2674554\ttotal: 4m 18s\tremaining: 21.3s\n",
      "449:\tlearn: 0.2672758\ttotal: 4m 19s\tremaining: 20.7s\n",
      "450:\tlearn: 0.2671800\ttotal: 4m 19s\tremaining: 20.1s\n",
      "451:\tlearn: 0.2669471\ttotal: 4m 20s\tremaining: 19.6s\n",
      "452:\tlearn: 0.2667282\ttotal: 4m 20s\tremaining: 19s\n",
      "453:\tlearn: 0.2665640\ttotal: 4m 21s\tremaining: 18.4s\n",
      "454:\tlearn: 0.2663757\ttotal: 4m 21s\tremaining: 17.8s\n",
      "455:\tlearn: 0.2662085\ttotal: 4m 22s\tremaining: 17.3s\n",
      "456:\tlearn: 0.2660326\ttotal: 4m 23s\tremaining: 16.7s\n",
      "457:\tlearn: 0.2658348\ttotal: 4m 23s\tremaining: 16.1s\n",
      "458:\tlearn: 0.2656328\ttotal: 4m 24s\tremaining: 15.5s\n",
      "459:\tlearn: 0.2654369\ttotal: 4m 24s\tremaining: 15s\n",
      "460:\tlearn: 0.2652929\ttotal: 4m 25s\tremaining: 14.4s\n",
      "461:\tlearn: 0.2651405\ttotal: 4m 26s\tremaining: 13.8s\n",
      "462:\tlearn: 0.2649207\ttotal: 4m 26s\tremaining: 13.2s\n",
      "463:\tlearn: 0.2647313\ttotal: 4m 27s\tremaining: 12.7s\n",
      "464:\tlearn: 0.2646012\ttotal: 4m 27s\tremaining: 12.1s\n",
      "465:\tlearn: 0.2643679\ttotal: 4m 28s\tremaining: 11.5s\n",
      "466:\tlearn: 0.2642023\ttotal: 4m 28s\tremaining: 10.9s\n",
      "467:\tlearn: 0.2640089\ttotal: 4m 29s\tremaining: 10.4s\n",
      "468:\tlearn: 0.2638273\ttotal: 4m 30s\tremaining: 9.79s\n",
      "469:\tlearn: 0.2636673\ttotal: 4m 31s\tremaining: 9.22s\n",
      "470:\tlearn: 0.2635495\ttotal: 4m 31s\tremaining: 8.65s\n",
      "471:\tlearn: 0.2633906\ttotal: 4m 32s\tremaining: 8.07s\n",
      "472:\tlearn: 0.2632435\ttotal: 4m 33s\tremaining: 7.51s\n",
      "473:\tlearn: 0.2631060\ttotal: 4m 33s\tremaining: 6.93s\n",
      "474:\tlearn: 0.2629560\ttotal: 4m 34s\tremaining: 6.36s\n",
      "475:\tlearn: 0.2628022\ttotal: 4m 35s\tremaining: 5.78s\n",
      "476:\tlearn: 0.2624948\ttotal: 4m 35s\tremaining: 5.2s\n",
      "477:\tlearn: 0.2623790\ttotal: 4m 36s\tremaining: 4.62s\n",
      "478:\tlearn: 0.2622258\ttotal: 4m 36s\tremaining: 4.04s\n",
      "479:\tlearn: 0.2620638\ttotal: 4m 37s\tremaining: 3.47s\n",
      "480:\tlearn: 0.2619077\ttotal: 4m 38s\tremaining: 2.89s\n",
      "481:\tlearn: 0.2616983\ttotal: 4m 38s\tremaining: 2.31s\n",
      "482:\tlearn: 0.2614590\ttotal: 4m 39s\tremaining: 1.73s\n",
      "483:\tlearn: 0.2613509\ttotal: 4m 39s\tremaining: 1.16s\n",
      "484:\tlearn: 0.2611453\ttotal: 4m 40s\tremaining: 578ms\n",
      "485:\tlearn: 0.2610293\ttotal: 4m 40s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Best Hyperparameters: {'n_estimators': 486, 'learning_rate': 0.08564115269968339, 'max_depth': 5, 'l2_leaf_reg': 5.495063193351241, 'border_count': 113, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'leaf_estimation_iterations': 9, 'leaf_estimation_method': 'Gradient'}\n",
    "Best Score for Top 50,000: 0.8327044025157233\n",
    "'''\n",
    "scale_pos_weight = len(y[y == 0]) / len(y[y == 1])\n",
    "\n",
    "catboost_params = {\n",
    "    'n_estimators': 486,\n",
    "    'learning_rate': 0.08564115269968339,\n",
    "    'max_depth': 5,\n",
    "    'l2_leaf_reg': 5.495063193351241,\n",
    "    'border_count': 113,\n",
    "    'grow_policy': 'SymmetricTree',\n",
    "    'min_data_in_leaf': 8,\n",
    "    'leaf_estimation_iterations': 9,\n",
    "    'leaf_estimation_method': 'Gradient',\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "}\n",
    "\n",
    "best_catboost_classifier = cb.CatBoostClassifier(**catboost_params)\n",
    "\n",
    "best_catboost_classifier.fit(X_train_final, y_train_final)\n",
    "catboost_predictions = best_catboost_classifier.predict_proba(X_test_final)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_catboost = 0.7\n",
    "weight_xgb = 0.25\n",
    "weight_lgbm = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_predictions = best_catboost_classifier.predict_proba(X_test_final)[:, 1]\n",
    "xgb_predictions = best_xgb_classifier.predict_proba(X_test_final)[:, 1]\n",
    "lgbm_predictions = best_lgb_classifier.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "ensemble_predictions = (weight_catboost * catboost_predictions) + (weight_xgb * xgb_predictions) + (weight_lgbm * lgbm_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ti serve il classifier allora non puoi usare le tecniche che dicevi, falle invece per ogni algoritmo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
